{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ef836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "from datasets import get_dataset_config_names\n",
    "\n",
    "from src.config import Config\n",
    "from src.preprocess.data import Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68fcfae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformers v4.26.1\n",
      "Using datasets v2.10.1\n"
     ]
    }
   ],
   "source": [
    "from src.utils import *\n",
    "setup_chapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac708b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "for module in [\"farm.utils\", \"farm.infer\", \"haystack.reader.farm.FARMReader\",\n",
    "              \"farm.modeling.prediction_head\", \"elasticsearch\", \"haystack.eval\",\n",
    "               \"haystack.document_store.base\", \"haystack.retriever.base\", \n",
    "              \"farm.data_handler.dataset\"]:\n",
    "    module_logger = logging.getLogger(module)\n",
    "    module_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794baaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241892a7fd134df5a426b3cf78bd9493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domains = get_dataset_config_names(\"subjqa\")\n",
    "subjqa = load_dataset(\"subjqa\", \"electronics\")\n",
    "subjqa.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08682b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in train: 1295\n",
      "Number of questions in test: 358\n",
      "Number of questions in validation: 255\n"
     ]
    }
   ],
   "source": [
    "dfs = {split:ds[:] for split, ds in subjqa.flatten().items()}\n",
    "\n",
    "for split, df in dfs.items():\n",
    "    print(\"Number of questions in {}: {}\".format(split, df[\"id\"].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31731062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>answers.text</th>\n",
       "      <th>answers.answer_start</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>B005DKZTMG</td>\n",
       "      <td>Does the keyboard lightweight?</td>\n",
       "      <td>[this keyboard is compact]</td>\n",
       "      <td>[215]</td>\n",
       "      <td>I really like this keyboard.  I give it 4 star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>B00AAIPT76</td>\n",
       "      <td>How is the battery?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I bought this after the first spare gopro batt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                        question                answers.text  \\\n",
       "791   B005DKZTMG  Does the keyboard lightweight?  [this keyboard is compact]   \n",
       "1159  B00AAIPT76             How is the battery?                          []   \n",
       "\n",
       "     answers.answer_start                                            context  \n",
       "791                 [215]  I really like this keyboard.  I give it 4 star...  \n",
       "1159                   []  I bought this after the first spare gopro batt...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_cols = [\"title\", \"question\", \"answers.text\", \"answers.answer_start\", \"context\"]\n",
    "sample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e2baac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this keyboard is compact'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = sample_df[\"answers.answer_start\"].iloc[0][0]\n",
    "end_idx = start_idx + len(sample_df[\"answers.text\"].iloc[0][0])\n",
    "\n",
    "sample_df[\"context\"].iloc[0][start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4448074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = {}\n",
    "question_types = [\"What\", \"How\", \"Is\", \"Does\", \"Do\", \"Was\", \"Where\", \"Why\"]\n",
    "\n",
    "for q in question_types:\n",
    "    counts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()[True]\n",
    "    \n",
    "pd.Series(counts).sort_values().plot.barh()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1121de86",
   "metadata": {},
   "source": [
    "### Answers from Text Framework\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/nlp-with-transformers/notebooks/48e4a5e5c44b86e1593c0945a49af9675cfd7158//images/chapter07_qa-head.png\" alt=\"\" width=800 height=400>\n",
    "\n",
    "- There are over 100 of questions & answering models in huggingface hub\n",
    "<img src=\"https://raw.githubusercontent.com/nlp-with-transformers/notebooks/48e4a5e5c44b86e1593c0945a49af9675cfd7158//images/chapter07_squad-models.png\" alt=\"\" width=600 height=300>\n",
    "\n",
    "- 4 models will be tested:\n",
    " <table>\n",
    "  <tr>\n",
    "    <th>Transformer</th>\n",
    "    <th>Description</th>\n",
    "    <th>Number of Parameters</th>\n",
    "    <th>F1 Score on SQuAD 2.0</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>MiniLM</td>\n",
    "    <td>RoBERTa-base</td>\n",
    "    <td>ALBERT-XXL</td>\n",
    "    <td>XLM-RoBERTa-large</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>A distilled version of BERT-base that preserved 99% of the performance while being twice a fast</td>\n",
    "    <td>RoBERTa models have better performance than their BERT counterparts and can be fine-tuned on most QA datasets using a single GPU</td>\n",
    "    <td>State-of-art performance on SQUaD 2.0, but computationallu intensive and difficult to deploy</td>\n",
    "    <td>Multilingual model for 100 languages with strong zero-shot performance</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>66M</td>\n",
    "    <td>125M</td>\n",
    "    <td>235M</td>\n",
    "    <td>570M</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>79.5</td>\n",
    "    <td>83.0</td>\n",
    "    <td>88.1</td>\n",
    "    <td>83.8</td>\n",
    "  </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa22306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering,  AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3de5d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepset/minilm-uncased-squad2\"\n",
    "model_ckpt = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "967abc2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'BertForQuestionAnswering(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n      (position_embeddings): Embedding(512, 384)\n      (token_type_embeddings): Embedding(2, 384)\n      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (qa_outputs): Linear(in_features=384, out_features=2, bias=True)\n)'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(model_ckpt)\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\07-Chatbot\\chatbot_venv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:598\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    597\u001b[0m \u001b[39m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[1;32m--> 598\u001b[0m tokenizer_config \u001b[39m=\u001b[39m get_tokenizer_config(pretrained_model_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m tokenizer_config:\n\u001b[0;32m    600\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tokenizer_config[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\07-Chatbot\\chatbot_venv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:442\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[1;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39mLoads the tokenizer configuration from a pretrained model tokenizer configuration.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mtokenizer_config = get_tokenizer_config(\"tokenizer-test\")\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39m```\"\"\"\u001b[39;00m\n\u001b[0;32m    441\u001b[0m commit_hash \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 442\u001b[0m resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[0;32m    443\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m    444\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[0;32m    445\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    446\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    447\u001b[0m     resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    448\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    449\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    450\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    451\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    452\u001b[0m     subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[0;32m    453\u001b[0m     _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    454\u001b[0m     _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    455\u001b[0m     _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[0;32m    456\u001b[0m )\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m resolved_config_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\07-Chatbot\\chatbot_venv\\lib\\site-packages\\transformers\\utils\\hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    406\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 409\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    410\u001b[0m         path_or_repo_id,\n\u001b[0;32m    411\u001b[0m         filename,\n\u001b[0;32m    412\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    413\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    414\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    415\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    416\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    417\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    418\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    419\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    420\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    423\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m    424\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    425\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    426\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\07-Chatbot\\chatbot_venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:112\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mfor\u001b[39;00m arg_name, arg_value \u001b[39min\u001b[39;00m chain(\n\u001b[0;32m    108\u001b[0m     \u001b[39mzip\u001b[39m(signature\u001b[39m.\u001b[39mparameters, args),  \u001b[39m# Args values\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     kwargs\u001b[39m.\u001b[39mitems(),  \u001b[39m# Kwargs values\u001b[39;00m\n\u001b[0;32m    110\u001b[0m ):\n\u001b[0;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 112\u001b[0m         validate_repo_id(arg_value)\n\u001b[0;32m    114\u001b[0m     \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m         has_token \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kewjs\\Documents\\02-Self_Learning\\01-Data_Science\\07-Chatbot\\chatbot_venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:166\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    167\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must use alphanumeric chars or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m forbidden, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m cannot start or end the name, max length is 96:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    169\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m--\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m repo_id \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m repo_id:\n\u001b[0;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot have -- or .. in repo_id: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'BertForQuestionAnswering(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n      (position_embeddings): Embedding(512, 384)\n      (token_type_embeddings): Embedding(2, 384)\n      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (qa_outputs): Linear(in_features=384, out_features=2, bias=True)\n)'."
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91fcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
